{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import json\n",
    "import collections\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = '/Users/Sp0t/Desktop/6998-Adv-ML-Final-Proj/'\n",
    "INPUT_DATA_PATH = PROJECT_PATH + 'mpd.v1/data/'\n",
    "PROC_DATA_PATH = PROJECT_PATH + 'mpd_proc/'\n",
    "OUTPUT_DATA_PATH = PROJECT_PATH + 'data_2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, track frequency of tracks and artists and record descriptive track info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_counts = collections.Counter()\n",
    "artist_counts = collections.Counter()\n",
    "track_info = {}\n",
    "\n",
    "for fname in os.listdir(INPUT_DATA_PATH):\n",
    "    data = json.loads(open(os.path.join(INPUT_DATA_PATH, fname)).read())\n",
    "    \n",
    "    for playlist in data['playlists']:\n",
    "        for track in playlist['tracks']:\n",
    "            track_id = track['track_uri'].split(':')[-1]\n",
    "            track_counts[track_id] += 1\n",
    "            \n",
    "            artist_name = track['artist_name']\n",
    "            artist_counts[artist_name] += 1\n",
    "            \n",
    "            track_info[track_id] = {\n",
    "                'track_name': track['track_name'],\n",
    "                'artist_name': artist_name,\n",
    "                'album_name': track['album_name'],\n",
    "                'duration': track['duration_ms']\n",
    "            }\n",
    "\n",
    "if not os.path.exists(OUTPUT_DATA_PATH):\n",
    "    os.makedirs(OUTPUT_DATA_PATH)\n",
    "            \n",
    "with open(OUTPUT_DATA_PATH + 'track_counts.json', 'w') as f:\n",
    "    json.dump(dict(track_counts), f)\n",
    "    \n",
    "with open(OUTPUT_DATA_PATH + 'artist_counts.json', 'w') as f:\n",
    "    json.dump(dict(artist_counts), f)\n",
    "    \n",
    "with open(OUTPUT_DATA_PATH + 'track_info_dict.json', 'w') as f:\n",
    "    json.dump(track_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load track count info. Filter out infrequent tracks (below track_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = collections.Counter(json.loads(open(OUTPUT_DATA_PATH + 'track_counts.json').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_threshold = 25\n",
    "common_track_counts = collections.Counter({k:c for k, c in track_counts.items() if c > track_threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_track_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load artist count info. Filter out infrequent artists (below artist_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_counts = collections.Counter(json.loads(open(OUTPUT_DATA_PATH + 'artist_counts.json').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_threshold = 40\n",
    "common_artist_counts = collections.Counter({k:c for k, c in artist_counts.items() if c > artist_threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40588"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_artist_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping of Spotify track ids to internal integer mapping (from 1 to M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_track_ids = common_track_counts.keys()\n",
    "track_id_map = dict(zip(valid_track_ids, range(len(valid_track_ids))))\n",
    "rev_track_id_map = dict(zip(track_id_map.values(), track_id_map.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping of Spotify artist names to internal integer mapping (from 1 to M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_artist_names = common_artist_counts.keys()\n",
    "artist_id_map = dict(zip(valid_artist_names, range(len(valid_artist_names))))\n",
    "rev_artist_id_map = dict(zip(artist_id_map.values(), artist_id_map.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Parse data again, keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 532.7s\n"
     ]
    }
   ],
   "source": [
    "track_playlist_threshold = 10\n",
    "track_playlist_count = 0\n",
    "track_playlist_id_map = {}\n",
    "track_row_inds = []\n",
    "track_col_inds = []\n",
    "valid_track_id_set = set(valid_track_ids)\n",
    "\n",
    "artist_playlist_threshold = 4\n",
    "artist_playlist_count = 0\n",
    "artist_playlist_id_map = {}\n",
    "artist_row_inds = []\n",
    "artist_col_inds = []\n",
    "valid_artist_name_set = set(valid_artist_names)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for fname in os.listdir(INPUT_DATA_PATH):\n",
    "    data = json.loads(open(os.path.join(INPUT_DATA_PATH, fname)).read())\n",
    "    for playlist in data['playlists']:\n",
    "        valid_tracks = [track_id_map[track['track_uri'].split(':')[-1]] for track in playlist['tracks'] \\\n",
    "                        if track['track_uri'].split(':')[-1] in valid_track_id_set]\n",
    "        if len(valid_tracks) > track_playlist_threshold:\n",
    "            track_playlist_id_map[track_playlist_count] = playlist['pid']\n",
    "            track_row_inds += [track_playlist_count] * len(valid_tracks)\n",
    "            track_col_inds += valid_tracks\n",
    "            track_playlist_count += 1\n",
    "\n",
    "        valid_artists = [artist_id_map[track['artist_name']] for track in playlist['tracks'] \\\n",
    "                         if track['artist_name'] in valid_artist_name_set]\n",
    "        if len(valid_artists) > artist_playlist_threshold:\n",
    "            artist_playlist_id_map[artist_playlist_count] = playlist['pid']\n",
    "            artist_row_inds += [artist_playlist_count] * len(valid_artists)\n",
    "            artist_col_inds += valid_artists\n",
    "            artist_playlist_count += 1\n",
    "            \n",
    "end = time.time()\n",
    "print (\"Time elapsed: {}s\".format(round(end-start, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data_thin = np.array([track_row_inds, track_col_inds]).T\n",
    "track_df = pd.DataFrame(track_data_thin)\n",
    "track_df.columns = ['playlist_id', 'track_id']\n",
    "\n",
    "artist_data_thin = np.array([artist_row_inds, artist_col_inds]).T\n",
    "artist_df = pd.DataFrame(artist_data_thin)\n",
    "artist_df.columns = ['playlist_id', 'artist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_to_delete = set(rev_track_id_map.keys()) - set(track_df['track_id'].unique())\n",
    "tracks_to_delete\n",
    "bad_spotify_track_ids = [rev_track_id_map[track] for track in tracks_to_delete]\n",
    "bad_spotify_track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_to_delete = set(rev_artist_id_map.keys()) - set(artist_df['artist_id'].unique())\n",
    "artists_to_delete\n",
    "bad_spotify_artist_names = [rev_artist_id_map[artist] for artist in artists_to_delete]\n",
    "bad_spotify_artist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_remaining_ids = track_df['track_id'].unique()\n",
    "\n",
    "new_valid_track_ids = [rev_track_id_map[track_id] for track_id in track_remaining_ids]\n",
    "new_track_id_map = dict(zip(new_valid_track_ids, range(len(new_valid_track_ids))))\n",
    "new_rev_track_id_map = dict(zip(new_track_id_map.values(), new_track_id_map.keys()))\n",
    "\n",
    "track_old_new_map = dict(zip(track_remaining_ids, new_rev_track_id_map.keys()))\n",
    "\n",
    "artist_remaining_ids = artist_df['artist_id'].unique()\n",
    "\n",
    "new_valid_artist_names = [rev_artist_id_map[artist_id] for artist_id in artist_remaining_ids]\n",
    "new_artist_id_map = dict(zip(new_valid_artist_names, range(len(new_valid_artist_names))))\n",
    "new_rev_artist_id_map = dict(zip(new_artist_id_map.values(), new_artist_id_map.keys()))\n",
    "\n",
    "artist_old_new_map = dict(zip(artist_remaining_ids, new_rev_artist_id_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['track_id'] = track_df['track_id'].apply(lambda x: track_old_new_map[x])\n",
    "artist_df['artist_id'] = artist_df['artist_id'].apply(lambda x: artist_old_new_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_row_inds = np.array(track_df['playlist_id'])\n",
    "track_col_inds = np.array(track_df['track_id'])\n",
    "track_data = sparse.coo_matrix(([1] * len(track_row_inds), (track_row_inds, track_col_inds)))\n",
    "\n",
    "artist_row_inds = np.array(artist_df['playlist_id'])\n",
    "artist_col_inds = np.array(artist_df['artist_id'])\n",
    "artist_data = sparse.coo_matrix(([1] * len(artist_row_inds), (artist_row_inds, artist_col_inds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(OUTPUT_DATA_PATH + 'track_raw_sparse_large.npz', track_data)\n",
    "sparse.save_npz(OUTPUT_DATA_PATH + 'artist_raw_sparse_large.npz', artist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_csv(OUTPUT_DATA_PATH + 'track_raw_df_large.csv')\n",
    "artist_df.to_csv(OUTPUT_DATA_PATH + 'artist_raw_df_large.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from sparse .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data = sparse.load_npz(OUTPUT_DATA_PATH + 'track_raw_sparse_large.npz')\n",
    "artist_data = sparse.load_npz(OUTPUT_DATA_PATH + 'artist_raw_sparse_large.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.DataFrame({'playlist_id': track_data.row, 'track_id': track_data.col})\n",
    "artist_df = pd.DataFrame({'playlist_id': artist_data.row, 'artist_id': artist_data.col})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_playlist = data.groupby('playlist_id')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_playlist):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            inds = np.zeros(n_items_u, dtype='bool')\n",
    "            inds[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).\n",
    "                 astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(inds)])\n",
    "            te_list.append(group[inds])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print('{:d} playlists sampled'.format(i))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 58908656 playlist inclusion events from 919695 playlist and 190897 tracks (sparsity: 0.034%)\n"
     ]
    }
   ],
   "source": [
    "track_sparsity = 1. * track_df.shape[0] / (track_data.shape[0] * track_data.shape[1])\n",
    "\n",
    "print(\"\"\"After filtering, there are {:d} playlist inclusion events from {:d} playlist and {:d} tracks \\\n",
    "(sparsity: {:.3f}%)\"\"\".format(\n",
    "    track_df.shape[0],\n",
    "    track_data.shape[0],\n",
    "    track_data.shape[1],\n",
    "    track_sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 64944204 playlist inclusion events from 997671 playlist and 40588 artists (sparsity: 0.160%)\n"
     ]
    }
   ],
   "source": [
    "artist_sparsity = 1. * artist_df.shape[0] / (artist_data.shape[0] * artist_data.shape[1])\n",
    "\n",
    "print(\"\"\"After filtering, there are {:d} playlist inclusion events from {:d} playlist and {:d} artists \\\n",
    "(sparsity: {:.3f}%)\"\"\".format(\n",
    "    artist_df.shape[0],\n",
    "    artist_data.shape[0],\n",
    "    artist_data.shape[1],\n",
    "    artist_sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_unique_pid = pd.unique(track_df['playlist_id'])\n",
    "track_inds_perm = np.random.permutation(track_unique_pid.size)\n",
    "track_unique_pid = track_unique_pid[track_inds_perm]\n",
    "\n",
    "artist_unique_pid = pd.unique(artist_df['playlist_id'])\n",
    "artist_inds_perm = np.random.permutation(artist_unique_pid.size)\n",
    "artist_unique_pid = artist_unique_pid[artist_inds_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_n_playlists = track_data.shape[0]\n",
    "track_n_heldout_playlists = 50000\n",
    "\n",
    "track_tr_playlists = track_unique_pid[:(track_n_playlists - track_n_heldout_playlists * 2)]\n",
    "track_vd_playlists = track_unique_pid[(track_n_playlists - track_n_heldout_playlists * 2):\n",
    "                                      (track_n_playlists - track_n_heldout_playlists)]\n",
    "track_te_playlists = track_unique_pid[(track_n_playlists - track_n_heldout_playlists):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_train_playlists = track_df.loc[track_df['playlist_id'].isin(track_tr_playlists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190897"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_unique_tid = pd.unique(track_train_playlists['track_id'])\n",
    "len(track_unique_tid)\n",
    "### THIS HAS TO MATCH THE ORIGINAL NUMBER OF UNIQUE TRACKS -- OTHERWISE RESAMPLE TRAINING PLAYLIST IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190897"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(track_df['track_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_n_playlists = artist_data.shape[0]\n",
    "artist_n_heldout_playlists = 15000\n",
    "\n",
    "artist_tr_playlists = artist_unique_pid[:(artist_n_playlists - artist_n_heldout_playlists * 2)]\n",
    "artist_vd_playlists = artist_unique_pid[(artist_n_playlists - artist_n_heldout_playlists * 2):\n",
    "                                        (artist_n_playlists - artist_n_heldout_playlists)]\n",
    "artist_te_playlists = artist_unique_pid[(artist_n_playlists - artist_n_heldout_playlists):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_train_playlists = artist_df.loc[artist_df['playlist_id'].isin(artist_tr_playlists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40588"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_unique_aid = pd.unique(artist_train_playlists['artist_id'])\n",
    "len(artist_unique_aid)\n",
    "### THIS HAS TO MATCH THE ORIGINAL NUMBER OF UNIQUE TRACKS -- OTHERWISE RESAMPLE TRAINING PLAYLIST IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40588"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(artist_df['artist_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_track2id = dict((tid, i) for (i, tid) in enumerate(track_unique_tid))\n",
    "track_playlist2id = dict((pid, i) for (i, pid) in enumerate(track_unique_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_artist2id = dict((aid, i) for (i, aid) in enumerate(artist_unique_aid))\n",
    "artist_playlist2id = dict((pid, i) for (i, pid) in enumerate(artist_unique_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_dir = os.path.join(PROC_DATA_PATH, 'data_2')\n",
    "\n",
    "if not os.path.exists(proc_dir):\n",
    "    os.makedirs(proc_dir)\n",
    "\n",
    "with open(os.path.join(proc_dir, 'track_unique_tid.txt'), 'w') as f:\n",
    "    for tid in track_unique_tid:\n",
    "        f.write('%s\\n' % tid)\n",
    "        \n",
    "with open(os.path.join(proc_dir, 'artist_unique_aid.txt'), 'w') as f:\n",
    "    for aid in artist_unique_aid:\n",
    "        f.write('%s\\n' % aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 playlists sampled\n",
      "1000 playlists sampled\n",
      "2000 playlists sampled\n",
      "3000 playlists sampled\n",
      "4000 playlists sampled\n",
      "5000 playlists sampled\n",
      "6000 playlists sampled\n",
      "7000 playlists sampled\n",
      "8000 playlists sampled\n",
      "9000 playlists sampled\n",
      "10000 playlists sampled\n",
      "11000 playlists sampled\n",
      "12000 playlists sampled\n",
      "13000 playlists sampled\n",
      "14000 playlists sampled\n",
      "15000 playlists sampled\n",
      "16000 playlists sampled\n",
      "17000 playlists sampled\n",
      "18000 playlists sampled\n",
      "19000 playlists sampled\n",
      "20000 playlists sampled\n",
      "21000 playlists sampled\n",
      "22000 playlists sampled\n",
      "23000 playlists sampled\n",
      "24000 playlists sampled\n",
      "25000 playlists sampled\n",
      "26000 playlists sampled\n",
      "27000 playlists sampled\n",
      "28000 playlists sampled\n",
      "29000 playlists sampled\n",
      "30000 playlists sampled\n",
      "31000 playlists sampled\n",
      "32000 playlists sampled\n",
      "33000 playlists sampled\n",
      "34000 playlists sampled\n",
      "35000 playlists sampled\n",
      "36000 playlists sampled\n",
      "37000 playlists sampled\n",
      "38000 playlists sampled\n",
      "39000 playlists sampled\n",
      "40000 playlists sampled\n",
      "41000 playlists sampled\n",
      "42000 playlists sampled\n",
      "43000 playlists sampled\n",
      "44000 playlists sampled\n",
      "45000 playlists sampled\n",
      "46000 playlists sampled\n",
      "47000 playlists sampled\n",
      "48000 playlists sampled\n",
      "49000 playlists sampled\n"
     ]
    }
   ],
   "source": [
    "track_vad_playlists = track_df.loc[track_df['playlist_id'].isin(track_vd_playlists)]\n",
    "track_vad_playlists = track_vad_playlists.loc[track_vad_playlists['track_id'].isin(track_unique_tid)]\n",
    "track_vad_playlists_tr, track_vad_playlists_te = split_train_test_proportion(track_vad_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 playlists sampled\n",
      "1000 playlists sampled\n",
      "2000 playlists sampled\n",
      "3000 playlists sampled\n",
      "4000 playlists sampled\n",
      "5000 playlists sampled\n",
      "6000 playlists sampled\n",
      "7000 playlists sampled\n",
      "8000 playlists sampled\n",
      "9000 playlists sampled\n",
      "10000 playlists sampled\n",
      "11000 playlists sampled\n",
      "12000 playlists sampled\n",
      "13000 playlists sampled\n",
      "14000 playlists sampled\n",
      "15000 playlists sampled\n",
      "16000 playlists sampled\n",
      "17000 playlists sampled\n",
      "18000 playlists sampled\n",
      "19000 playlists sampled\n",
      "20000 playlists sampled\n",
      "21000 playlists sampled\n",
      "22000 playlists sampled\n",
      "23000 playlists sampled\n",
      "24000 playlists sampled\n",
      "25000 playlists sampled\n",
      "26000 playlists sampled\n",
      "27000 playlists sampled\n",
      "28000 playlists sampled\n",
      "29000 playlists sampled\n",
      "30000 playlists sampled\n",
      "31000 playlists sampled\n",
      "32000 playlists sampled\n",
      "33000 playlists sampled\n",
      "34000 playlists sampled\n",
      "35000 playlists sampled\n",
      "36000 playlists sampled\n",
      "37000 playlists sampled\n",
      "38000 playlists sampled\n",
      "39000 playlists sampled\n",
      "40000 playlists sampled\n",
      "41000 playlists sampled\n",
      "42000 playlists sampled\n",
      "43000 playlists sampled\n",
      "44000 playlists sampled\n",
      "45000 playlists sampled\n",
      "46000 playlists sampled\n",
      "47000 playlists sampled\n",
      "48000 playlists sampled\n",
      "49000 playlists sampled\n"
     ]
    }
   ],
   "source": [
    "track_test_playlists = track_df.loc[track_df['playlist_id'].isin(track_te_playlists)]\n",
    "track_test_playlists = track_test_playlists.loc[track_test_playlists['track_id'].isin(track_unique_tid)]\n",
    "track_test_playlists_tr, track_test_playlists_te = split_train_test_proportion(track_test_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 playlists sampled\n",
      "1000 playlists sampled\n",
      "2000 playlists sampled\n",
      "3000 playlists sampled\n",
      "4000 playlists sampled\n",
      "5000 playlists sampled\n",
      "6000 playlists sampled\n",
      "7000 playlists sampled\n",
      "8000 playlists sampled\n",
      "9000 playlists sampled\n",
      "10000 playlists sampled\n",
      "11000 playlists sampled\n",
      "12000 playlists sampled\n",
      "13000 playlists sampled\n",
      "14000 playlists sampled\n"
     ]
    }
   ],
   "source": [
    "artist_vad_playlists = artist_df.loc[artist_df['playlist_id'].isin(artist_vd_playlists)]\n",
    "artist_vad_playlists = artist_vad_playlists.loc[artist_vad_playlists['artist_id'].isin(artist_unique_aid)]\n",
    "artist_vad_playlists_tr, artist_vad_playlists_te = split_train_test_proportion(artist_vad_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 playlists sampled\n",
      "1000 playlists sampled\n",
      "2000 playlists sampled\n",
      "3000 playlists sampled\n",
      "4000 playlists sampled\n",
      "5000 playlists sampled\n",
      "6000 playlists sampled\n",
      "7000 playlists sampled\n",
      "8000 playlists sampled\n",
      "9000 playlists sampled\n",
      "10000 playlists sampled\n",
      "11000 playlists sampled\n",
      "12000 playlists sampled\n",
      "13000 playlists sampled\n",
      "14000 playlists sampled\n"
     ]
    }
   ],
   "source": [
    "artist_test_playlists = artist_df.loc[artist_df['playlist_id'].isin(artist_te_playlists)]\n",
    "artist_test_playlists = artist_test_playlists.loc[artist_test_playlists['artist_id'].isin(artist_unique_aid)]\n",
    "artist_test_playlists_tr, artist_test_playlists_te = split_train_test_proportion(artist_test_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp, playlist2id, item2id, item_key_str):\n",
    "    pid = list(map(lambda x: playlist2id[x], tp['playlist_id']))\n",
    "    iid = list(map(lambda x: item2id[x], tp[item_key_str]))\n",
    "    return pd.DataFrame(data={'pid': pid, 'iid': iid}, columns=['pid', 'iid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_key_str = 'track_id'\n",
    "track_train_data = numerize(track_train_playlists, track_playlist2id, track_track2id, track_id_key_str)\n",
    "track_train_data.to_csv(os.path.join(proc_dir, 'track_train.csv'), index=False)\n",
    "\n",
    "track_vad_data_tr = numerize(track_vad_playlists_tr, track_playlist2id, track_track2id, track_id_key_str)\n",
    "track_vad_data_tr.to_csv(os.path.join(proc_dir, 'track_validation_tr.csv'), index=False)\n",
    "\n",
    "track_vad_data_te = numerize(track_vad_playlists_te, track_playlist2id, track_track2id, track_id_key_str)\n",
    "track_vad_data_te.to_csv(os.path.join(proc_dir, 'track_validation_te.csv'), index=False)\n",
    "\n",
    "track_test_data_tr = numerize(track_test_playlists_tr, track_playlist2id, track_track2id, track_id_key_str)\n",
    "track_test_data_tr.to_csv(os.path.join(proc_dir, 'track_test_tr.csv'), index=False)\n",
    "\n",
    "track_test_data_te = numerize(track_test_playlists_te, track_playlist2id, track_track2id, track_id_key_str)\n",
    "track_test_data_te.to_csv(os.path.join(proc_dir, 'track_test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_id_key_str = 'artist_id'\n",
    "artist_train_data = numerize(artist_train_playlists, artist_playlist2id, artist_artist2id, artist_id_key_str)\n",
    "artist_train_data.to_csv(os.path.join(proc_dir, 'artist_train.csv'), index=False)\n",
    "\n",
    "artist_vad_data_tr = numerize(artist_vad_playlists_tr, artist_playlist2id, artist_artist2id, artist_id_key_str)\n",
    "artist_vad_data_tr.to_csv(os.path.join(proc_dir, 'artist_validation_tr.csv'), index=False)\n",
    "\n",
    "artist_vad_data_te = numerize(artist_vad_playlists_te, artist_playlist2id, artist_artist2id, artist_id_key_str)\n",
    "artist_vad_data_te.to_csv(os.path.join(proc_dir, 'artist_validation_te.csv'), index=False)\n",
    "\n",
    "artist_test_data_tr = numerize(artist_test_playlists_tr, artist_playlist2id, artist_artist2id, artist_id_key_str)\n",
    "artist_test_data_tr.to_csv(os.path.join(proc_dir, 'artist_test_tr.csv'), index=False)\n",
    "\n",
    "artist_test_data_te = numerize(artist_test_playlists_te, artist_playlist2id, artist_artist2id, artist_id_key_str)\n",
    "artist_test_data_te.to_csv(os.path.join(proc_dir, 'artist_test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
