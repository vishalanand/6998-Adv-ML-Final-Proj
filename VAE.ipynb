{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anand_vishal2994/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anand_vishal2994/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, sys, bottleneck as bn, numpy as np, matplotlib.pyplot as plt, seaborn as sn, pandas as pd, tensorflow as tf\n",
    "from scipy import sparse\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "from tqdm import tqdm \n",
    "%matplotlib inline\n",
    "sn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])\n",
    "\n",
    "class MultiVAE(MultiDAE):\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "        sampled_z = mu_q + self.is_training_ph * epsilon * std_q\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])\n",
    "    \n",
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'track_id')\n",
    "        tp = tp[tp['track_id'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "        \n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'user_id')\n",
    "        tp = tp[tp['user_id'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    usercount, itemcount = get_count(tp, 'user_id'), get_count(tp, 'track_id') \n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user_id')\n",
    "    tr_list, te_list = list(), list()\n",
    "    np.random.seed(98765)\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis], idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum() for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG\n",
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "log directory: log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n",
      "chkpt directory: log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './mpd_proc'\n",
    "pro_dir = os.path.join(DATA_DIR, 'data_large')\n",
    "\n",
    "'''\n",
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'raw_df.csv'), header=0, index_col=0)\n",
    "print(raw_data.head())\n",
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "print(\"After filtering, there are %d playlist inclusion events from %d playlist and %d tracks (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
    "unique_uid = user_activity.index\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "train_plays = raw_data.loc[raw_data['user_id'].isin(tr_users)]\n",
    "unique_sid = pd.unique(train_plays['track_id'])\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)\n",
    "vad_plays = raw_data.loc[raw_data['user_id'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['track_id'].isin(unique_sid)]\n",
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
    "test_plays = raw_data.loc[raw_data['user_id'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['track_id'].isin(unique_sid)]\n",
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['user_id']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['track_id']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])\n",
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
    "'''\n",
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows), (rows, cols)), dtype='float64', shape=(n_users, n_items))\n",
    "    return data\n",
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))\n",
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te\n",
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'), os.path.join(pro_dir, 'validation_te.csv'))\n",
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "batch_size_vad = 2000\n",
    "total_anneal_steps = 200000\n",
    "anneal_cap = 0.2\n",
    "p_dims = [200, 600, n_items]\n",
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])\n",
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))\n",
    "log_dir = 'log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
    "chkpt_dir = 'log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2528028233088182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [1:01:03<29:30:55, 3663.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2773385169348196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [2:01:52<28:26:11, 3656.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.28514107836128355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [3:02:29<27:22:23, 3649.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2877635102507659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [4:02:20<26:15:16, 3635.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2894289363483962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [5:02:28<25:12:23, 3629.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.29026740384714667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [6:02:32<24:10:08, 3625.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2906367374929651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [7:04:42<23:15:27, 3640.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2923091770234611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [8:06:18<22:17:20, 3647.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2935296211985771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [9:08:21<21:19:29, 3655.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2940164279388915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [10:10:03<20:20:06, 3660.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2950775339477392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [11:10:07<19:17:29, 3655.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2952978016679643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [12:11:27<18:17:11, 3657.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2959812079627227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [13:11:57<17:15:37, 3655.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.29632774578176385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [14:12:09<16:13:53, 3652.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2973348004488285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [15:12:06<15:12:06, 3648.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.297735507509952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [16:12:52<14:11:16, 3648.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.29857936849030725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [17:14:27<13:11:03, 3651.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.2988425475904765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [19:19:28<11:11:16, 3661.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.29879389587195565\n",
      "NDCG: 0.2992937517762903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [20:20:19<10:10:09, 3661.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.30042770327091356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [22:22:58<8:08:21, 3662.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.3001702678914034\n",
      "NDCG: 0.3011571315079568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [24:24:24<6:06:06, 3661.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.3004840363856095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [25:25:31<5:05:06, 3661.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.30107621088313996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [26:28:05<4:04:19, 3664.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.3008230754160175\n",
      "NDCG: 0.3013458507887182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [27:29:59<3:03:19, 3666.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.3021236588708264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [29:34:21<1:01:11, 3671.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.30194381656071817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 30/30 [30:36:14<00:00, 3672.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.3015307420706739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ndcgs_vad = []\n",
    "idxlist = list(idxlist)\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    best_ndcg = -np.inf\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        np.random.shuffle(idxlist)\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        print (\"NDCG: {}\".format(ndcg_))\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "chkpt directory: log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n",
      "INFO:tensorflow:Restoring parameters from log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4000ac518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "test_data_tr,test_data_te=load_tr_te_data(os.path.join(pro_dir,'test_tr.csv'),os.path.join(pro_dir,'test_te.csv'))\n",
    "\n",
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "batch_size_test = 2000\n",
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()\n",
    "#chkpt_dir = 'chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "chkpt_dir = 'log/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)\n",
    "n100_list, r20_list, r50_list, r100_list = [], [], [], []\n",
    "chkpt_dir_1 = \"log/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\"\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir_1))\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "        r100_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "    \n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)\n",
    "r100_list = np.concatenate(r100_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.30001 (0.00099)\n",
      "Test Recall@20=0.24256 (0.00102)\n",
      "Test Recall@50=0.34199 (0.00114)\n",
      "Test Recall@100=0.43905 (0.00120)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))\n",
    "print(\"Test Recall@100=%.5f (%.5f)\" % (np.mean(r100_list), np.std(r100_list) / np.sqrt(len(r100_list))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
